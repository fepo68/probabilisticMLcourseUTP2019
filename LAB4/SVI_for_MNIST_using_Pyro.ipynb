{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Variational Inference for Neural Networks using Pyro\n",
    "\n",
    "## Advanced topics on machine learning\n",
    " UNIVERSIDAD TECNOLÓGICA DE PEREIRA\n",
    " \n",
    "Mauricio A. Álvarez PhD\n",
    "\n",
    "TA: Cristian Guarnizo PhD and Hernan F. García PhD (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory <br>\n",
    "\n",
    "This notebook is based on [Stochastic Variantional Inference](https://arxiv.org/abs/1206.7051) (SVI), which is already coded in Pyro. We use SVI in order to estimate the posterior for the weights of Deep Neural Networks. An example of SVI application using Pyro is given in [https://pyro.ai/examples/svi_part_i.html](https://pyro.ai/examples/svi_part_i.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by installing PyTorch and Pyro, if you already have these packages installed then skip the following step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://download.pytorch.org/whl/cu100/torch-1.1.0-cp37-cp37m-win_amd64.whl\n",
    "!pip install https://download.pytorch.org/whl/cu100/torchvision-0.3.0-cp37-cp37m-win_amd64.whl\n",
    "!pip install pyro-ppl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed to import most of the libraries that we need for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mWDRDFu4S0Zf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QF6XvBFTS0Zi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython import display\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from  imageio import imread\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NboZXAs6S0Zl"
   },
   "source": [
    "Next, we define our Neural Network model using Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mdwbaf_yS0Zn"
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "     def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(output)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yKkZCuSAS0Zp"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "        batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "        batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST consists of images of 28x28 pixels that contain numbers from 0 to 9. The idea is to classify each image to its corresponding number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIetdhcKS0Zt"
   },
   "outputs": [],
   "source": [
    "net = NN(28*28, 1024, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we import Pyro library that allows to do Probabilistic Programming using PyTorch. Additionally, we import the methods that we will use, such as, SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ESdE6KTnS0Zx"
   },
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal, Categorical\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our NN output is defined by a SoftMax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEClCTF9S0Z0"
   },
   "outputs": [],
   "source": [
    "log_softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the priors for all the weights of our NN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_FDJeGdS0Z2"
   },
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    fc1w_prior = Normal(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
    "    \n",
    "    outw_prior = Normal(loc=torch.zeros_like(net.out.weight), scale=torch.ones_like(net.out.weight))\n",
    "    outb_prior = Normal(loc=torch.zeros_like(net.out.bias), scale=torch.ones_like(net.out.bias))\n",
    "    \n",
    "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,  'out.weight': outw_prior, 'out.bias': outb_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    \n",
    "    lhat = log_softmax(lifted_reg_model(x_data))\n",
    "    \n",
    "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define the \"guide\" that indicates how we sample the weights from each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSXzyIj_S0Z5"
   },
   "outputs": [],
   "source": [
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(x_data, y_data):\n",
    "    \n",
    "    # First layer weight distribution priors\n",
    "    fc1w_mu = torch.randn_like(net.fc1.weight)\n",
    "    fc1w_sigma = torch.randn_like(net.fc1.weight)\n",
    "    fc1w_mu_param = pyro.param(\"fc1w_mu\", fc1w_mu)\n",
    "    fc1w_sigma_param = softplus(pyro.param(\"fc1w_sigma\", fc1w_sigma))\n",
    "    fc1w_prior = Normal(loc=fc1w_mu_param, scale=fc1w_sigma_param)\n",
    "    # First layer bias distribution priors\n",
    "    fc1b_mu = torch.randn_like(net.fc1.bias)\n",
    "    fc1b_sigma = torch.randn_like(net.fc1.bias)\n",
    "    fc1b_mu_param = pyro.param(\"fc1b_mu\", fc1b_mu)\n",
    "    fc1b_sigma_param = softplus(pyro.param(\"fc1b_sigma\", fc1b_sigma))\n",
    "    fc1b_prior = Normal(loc=fc1b_mu_param, scale=fc1b_sigma_param)\n",
    "    # Output layer weight distribution priors\n",
    "    outw_mu = torch.randn_like(net.out.weight)\n",
    "    outw_sigma = torch.randn_like(net.out.weight)\n",
    "    outw_mu_param = pyro.param(\"outw_mu\", outw_mu)\n",
    "    outw_sigma_param = softplus(pyro.param(\"outw_sigma\", outw_sigma))\n",
    "    outw_prior = Normal(loc=outw_mu_param, scale=outw_sigma_param).independent(1)\n",
    "    # Output layer bias distribution priors\n",
    "    outb_mu = torch.randn_like(net.out.bias)\n",
    "    outb_sigma = torch.randn_like(net.out.bias)\n",
    "    outb_mu_param = pyro.param(\"outb_mu\", outb_mu)\n",
    "    outb_sigma_param = softplus(pyro.param(\"outb_sigma\", outb_sigma))\n",
    "    outb_prior = Normal(loc=outb_mu_param, scale=outb_sigma_param)\n",
    "    priors = {'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior, 'out.weight': outw_prior, 'out.bias': outb_prior}\n",
    "    \n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    \n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose as our optimizer Adam, and define the inference model based on SVI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyriuRj2S0Z7"
   },
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to only perform 5 iterations of the SVI learning model, because the evaluation of this model is quite expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kW2Cm-y7S0Z9",
    "outputId": "d9ff4e5f-253c-4479-dc5b-726caafcd868"
   },
   "outputs": [],
   "source": [
    "num_iterations = 5\n",
    "loss = 0\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = 0\n",
    "    for batch_id, data in enumerate(train_loader):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss += svi.step(data[0].view(-1,28*28), data[1])\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = loss / normalizer_train\n",
    "    \n",
    "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training step, we proceed to test our model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "27vBE6P2S0Z_",
    "outputId": "feaaa11b-5d98-4d6f-b1dd-402e74ea2bb2"
   },
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "def predict(x):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    mean = torch.mean(torch.stack(yhats), 0)\n",
    "    return np.argmax(mean.numpy(), axis=1)\n",
    "\n",
    "print('Prediction when network is forced to predict')\n",
    "correct = 0\n",
    "total = 0\n",
    "for j, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    predicted = predict(images.view(-1,28*28))\n",
    "    total += labels.size(0)\n",
    "    #torch.from_numpy(img).float().to(device)\n",
    "    correct += (torch.from_numpy(predicted) == labels).sum().item()\n",
    "print(\"accuracy: %d %%\" % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our targets or clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83YivLYgS0aC"
   },
   "outputs": [],
   "source": [
    "classes = ('0', '1', '2', '3',\n",
    "           '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will allow us to plot the images of the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tte45m0hS0aF"
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    #plt.imshow(npimg,  cmap='gray')\n",
    "    #fig.show(figsize=(1,1))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(1, 1))\n",
    "    ax.imshow(npimg,  cmap='gray', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that allow us to evaluate 100 times the prediction of our model in order to have estimate its uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euduAC8kS0aI"
   },
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "def give_uncertainities(x):\n",
    "    sampled_models = [guide(None, None) for _ in range(num_samples)]\n",
    "    yhats = [F.log_softmax(model(x.view(-1,28*28)).data, 1).detach().numpy() for model in sampled_models]\n",
    "    return np.asarray(yhats)\n",
    "    #mean = torch.mean(torch.stack(yhats), 0)\n",
    "    #return np.argmax(mean, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we define a function to test a batch of samples. This function will plot the label as \"Real\", the image and the histograms regarding each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jG-bKsCzS0aL"
   },
   "outputs": [],
   "source": [
    "def test_batch(images, labels, plot=True):\n",
    "    y = give_uncertainities(images)\n",
    "    predicted_for_images = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for i in range(len(labels)):\n",
    "    \n",
    "        if(plot):\n",
    "            print(\"Real: \",labels[i].item())\n",
    "            fig, axs = plt.subplots(1, 10, sharey=True,figsize=(20,2))\n",
    "    \n",
    "        all_digits_prob = []\n",
    "    \n",
    "        highted_something = False\n",
    "    \n",
    "        for j in range(len(classes)):\n",
    "        \n",
    "            highlight=False\n",
    "        \n",
    "            histo = []\n",
    "            histo_exp = []\n",
    "        \n",
    "            for z in range(y.shape[0]):\n",
    "                histo.append(y[z][i][j])\n",
    "                histo_exp.append(np.exp(y[z][i][j]))\n",
    "            \n",
    "            prob = np.percentile(histo_exp, 50) #sampling median probability\n",
    "        \n",
    "            if(prob>0.2): #select if network thinks this sample is 20% chance of this being a label\n",
    "                highlight = True #possibly an answer\n",
    "        \n",
    "            all_digits_prob.append(prob)\n",
    "            \n",
    "            if(plot):\n",
    "            \n",
    "                N, bins, patches = axs[j].hist(histo, bins=8, color = \"lightgray\", lw=0,  weights=np.ones(len(histo)) / len(histo), density=False)\n",
    "                axs[j].set_title(str(j)+\" (\"+str(round(prob,2))+\")\") \n",
    "        \n",
    "            if(highlight):\n",
    "            \n",
    "                highted_something = True\n",
    "                \n",
    "                if(plot):\n",
    "\n",
    "                    # We'll color code by height, but you could use any scalar\n",
    "                    fracs = N / N.max()\n",
    "\n",
    "                    # we need to normalize the data to 0..1 for the full range of the colormap\n",
    "                    norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "                    # Now, we'll loop through our objects and set the color of each accordingly\n",
    "                    for thisfrac, thispatch in zip(fracs, patches):\n",
    "                        color = plt.cm.viridis(norm(thisfrac))\n",
    "                        thispatch.set_facecolor(color)\n",
    "\n",
    "    \n",
    "        if(plot):\n",
    "            plt.show()\n",
    "    \n",
    "        predicted = np.argmax(all_digits_prob)\n",
    "    \n",
    "        if(highted_something):\n",
    "            predicted_for_images+=1\n",
    "            if(labels[i].item()==predicted):\n",
    "                if(plot):\n",
    "                    print(\"Correct\")\n",
    "                correct_predictions +=1.0\n",
    "            else:\n",
    "                if(plot):\n",
    "                    print(\"Incorrect :()\")\n",
    "        else:\n",
    "            if(plot):\n",
    "                print(\"Undecided.\")\n",
    "        \n",
    "        if(plot):\n",
    "            imshow(images[i].squeeze())\n",
    "        \n",
    "    \n",
    "    if(plot):\n",
    "        print(\"Summary\")\n",
    "        print(\"Total images: \",len(labels))\n",
    "        print(\"Predicted for: \",predicted_for_images)\n",
    "        print(\"Accuracy when predicted: \",correct_predictions/predicted_for_images)\n",
    "        \n",
    "    return len(labels), correct_predictions, predicted_for_images \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our model performance using the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Wf4t8DWJS0aQ",
    "outputId": "4b019dba-b189-45ee-f95b-f4fecf408fc6"
   },
   "outputs": [],
   "source": [
    "# Prediction when network can decide not to predict\n",
    "\n",
    "print('Prediction when network can refuse')\n",
    "correct = 0\n",
    "total = 0\n",
    "total_predicted_for = 0\n",
    "for j, data in enumerate(test_loader):\n",
    "    images, labels = data\n",
    "    \n",
    "    total_minibatch, correct_minibatch, predictions_minibatch = test_batch(images, labels, plot=False)\n",
    "    total += total_minibatch\n",
    "    correct += correct_minibatch\n",
    "    total_predicted_for += predictions_minibatch\n",
    "\n",
    "print(\"Total images: \", total)\n",
    "print(\"Skipped: \", total-total_predicted_for)\n",
    "print(\"Accuracy when made predictions: %d %%\" % (100 * correct / total_predicted_for))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bEGehJdWS0aT"
   },
   "outputs": [],
   "source": [
    "# preparing for evaluation\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 28002
    },
    "colab_type": "code",
    "id": "FnODZrTvS0aU",
    "outputId": "1d9ebdbc-72a4-48ac-b272-b774c3b32b34"
   },
   "outputs": [],
   "source": [
    "test_batch(images[:100], labels[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test over random data\n",
    "\n",
    "Next we test how this model behaves when random data is given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxT21vITS0aW"
   },
   "outputs": [],
   "source": [
    "# generate random data\n",
    "num_random_samples = 20\n",
    "images_random = torch.rand(num_random_samples,28,28)\n",
    "labels_random = torch.randint(0,10, (num_random_samples,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6023
    },
    "colab_type": "code",
    "id": "6ULDmHVYS0aY",
    "outputId": "970eabfb-dc3a-4ecd-cf2c-13a1672ae9d1"
   },
   "outputs": [],
   "source": [
    "test_batch(images_random, labels_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test over characters differente from numbers\n",
    "\n",
    "Next we test how this model behaves when no numeric images are given as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNN9nkkLS0aa"
   },
   "outputs": [],
   "source": [
    "class data_loader(Dataset):\n",
    "\tdef __init__(self, root):\n",
    "\t\tImages, Y = [], []\n",
    "\t\tfolders = os.listdir(root)\n",
    "\t\tfolders = folders[1:]\n",
    "\n",
    "\t\tfor folder in folders:\n",
    "            \n",
    "\t\t\tfolder_path = os.path.join(root, folder)\n",
    "\t\t\tprint(folder_path)\n",
    "            \n",
    "            \n",
    "            \n",
    "\t\t\tfor ims in os.listdir(folder_path):\n",
    "\n",
    "\t\t\t\timg_path = os.path.join(folder_path, ims)\n",
    "\t\t\t\tImages.append(np.array(imread(img_path)))\n",
    "\t\t\t\tY.append(ord(folder) - 65)  # Folders are A-J so labels will be 0-9\n",
    "\t\t\t\t\n",
    "\t\tdata = [(x, y) for x, y in zip(Images, Y)]\n",
    "\t\tself.data = data\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.data)\n",
    "\n",
    "\tdef __getitem__(self, index):\n",
    "\t\timg = self.data[index][0]\n",
    "\n",
    "\t\t# 8 bit images. Scale between 0, 1\n",
    "\t\timg = img.reshape(1, 28, 28) / 255\n",
    "\n",
    "\t\t# Input for Conv2D should be Channels x Height x Width\n",
    "\t\timg_tensor = transforms.ToTensor()(img).view(1, 28, 28).float()\n",
    "\t\tlabel = self.data[index][1]\n",
    "\t\treturn (img_tensor, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "5ocNCiVwS0ac",
    "outputId": "87675572-d4b3-474a-cbcb-96660d9fdc30"
   },
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "r = requests.get('https://github.com/fepo68/probabilisticMLcourseUTP2019/blob/master/LAB4/not-mnist.zip?raw=true')\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()\n",
    "\n",
    "# NOT Mnist data\n",
    "test_dataset_notmnist = data_loader('not-mnist')\n",
    "test_loader_notmnist = DataLoader(test_dataset_notmnist, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Dcpbz9XhS0ag",
    "outputId": "696c97f2-088c-4075-b07c-ce984e844bf0"
   },
   "outputs": [],
   "source": [
    "# Prediction when network can decide not to predict\n",
    "\n",
    "print('Prediction on not-MNIST when network can refuse')\n",
    "total = 0\n",
    "total_predicted_for = 0\n",
    "for j, data in enumerate(test_loader_notmnist):\n",
    "    images, labels = data\n",
    "    total_minibatch, correct_minibatch, predictions_minibatch = test_batch(images, labels, plot=False)\n",
    "    total += total_minibatch\n",
    "    total_predicted_for += predictions_minibatch\n",
    "\n",
    "print(\"Total images: \", total)\n",
    "print(\"Skipped: \", total-total_predicted_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3v9YFcaVS0ai"
   },
   "outputs": [],
   "source": [
    "dataiter_notmnist = iter(test_loader_notmnist)\n",
    "images_notmnist, labels_notmnist = dataiter_notmnist.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 28002
    },
    "colab_type": "code",
    "id": "2Psy-Q8wS0ak",
    "outputId": "d841fb4b-d925-44d0-d8bb-17e84757a6c7"
   },
   "outputs": [],
   "source": [
    "test_batch(images_notmnist[:100], labels_notmnist[:100])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "bnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
