{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mA83yBhMdbGz"
   },
   "source": [
    "\n",
    "# Monte-Carlo Dropout for uncertainty prediction on CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAF9fAYqdbG0"
   },
   "source": [
    "## Advanced topics on machine learning\n",
    " UNIVERSIDAD TECNOLÓGICA DE PEREIRA\n",
    " \n",
    "Mauricio A. Álvarez Phd\n",
    "\n",
    "TA: Cristian D. Guarnizo PhD and Hernan F. García PhD (c)\n",
    "\n",
    "\n",
    "\n",
    "We test the Monte-Carlo dropout for uncertainty prediction according to https://arxiv.org/pdf/1506.02142.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZ8Oz7BhdbG1"
   },
   "source": [
    "Therefore we train a model on CIFAR10 using dropout and then at inference time we keep using dropout to estimate the uncertainty of the network by performing several forward passes through the network for each sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hz9-XF7ndbG2"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "N1nX5MVDdbG2",
    "outputId": "6f255171-acb7-49ab-b1ef-f0472df094ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpMKvvDGdbG6"
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K_uXQCTadbG7"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "mc_samples = 10 # number of samples for prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2aPZB0_dbG9"
   },
   "source": [
    "# Load and preprocess CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "nl6bS26odbG-",
    "outputId": "e9f075e4-e908-48d4-bde9-6f74653eea51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 4s 0us/step\n",
      "shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "img_rows, img_cols = x_train.shape[1], x_train.shape[2]\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmEbKdQjdbHB"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "65ZEl1qcdbHC"
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Use only minimalistic model to get some statistics for misclassifications\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(128, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(256, kernel_size=(3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=input_shape))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # This dropout layer stays active during testing phase\n",
    "    model.add(Lambda(lambda x: K.dropout(x, level=0.25)))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    \n",
    "    model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                optimizer=keras.optimizers.Adadelta(),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "skPA97vrdbHE",
    "outputId": "acdd1656-9ca9-42ba-966e-c8fd982ebb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "colab_type": "code",
    "id": "5YCly41HdbHG",
    "outputId": "2576c6c4-2248-43e4-d751-eb3562100551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 94s 2ms/step - loss: 1.9512 - acc: 0.2832 - val_loss: 1.7591 - val_acc: 0.3754\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 1.4913 - acc: 0.4603 - val_loss: 1.3709 - val_acc: 0.4960\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 1.2825 - acc: 0.5420 - val_loss: 1.2680 - val_acc: 0.5574\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 1.1586 - acc: 0.5888 - val_loss: 1.1099 - val_acc: 0.6053\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 1.0634 - acc: 0.6237 - val_loss: 1.0900 - val_acc: 0.6151\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.9872 - acc: 0.6516 - val_loss: 1.0268 - val_acc: 0.6387\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.9170 - acc: 0.6812 - val_loss: 0.9963 - val_acc: 0.6503\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.8654 - acc: 0.7001 - val_loss: 1.0563 - val_acc: 0.6415\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.8151 - acc: 0.7168 - val_loss: 1.0180 - val_acc: 0.6556\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.7746 - acc: 0.7311 - val_loss: 0.9277 - val_acc: 0.6844\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7448 - acc: 0.7396 - val_loss: 0.8969 - val_acc: 0.7007\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 92s 2ms/step - loss: 0.7092 - acc: 0.7530 - val_loss: 0.8859 - val_acc: 0.6960\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6776 - acc: 0.7634 - val_loss: 0.9004 - val_acc: 0.6999\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6506 - acc: 0.7708 - val_loss: 0.8976 - val_acc: 0.7047\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 93s 2ms/step - loss: 0.6248 - acc: 0.7797 - val_loss: 0.9123 - val_acc: 0.6970\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.6010 - acc: 0.7897 - val_loss: 0.9010 - val_acc: 0.7020\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 91s 2ms/step - loss: 0.5776 - acc: 0.7987 - val_loss: 0.9468 - val_acc: 0.6986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f935035e0b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test, y_test),\n",
    "            callbacks=[EarlyStopping(patience=5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSsan7AXdbHJ"
   },
   "source": [
    "# Evaluate Uncertainty Prediction with Monte Carlo Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r8sBmU0ldbHK"
   },
   "source": [
    "Evaluate on test set and compare mean standard deviation of all predictions to mean standard deviation of misclassified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vcaq3yT-dbHL"
   },
   "outputs": [],
   "source": [
    "def get_predictions_with_uncertainty(model, X):\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(mc_samples): # can be made more efficient by just forward passing several times through the last layer\n",
    "        predictions.append(model.predict(X))\n",
    "    predictions = np.array(predictions)\n",
    "    \n",
    "    means = np.mean(predictions, axis=0)\n",
    "    std = np.std(predictions, axis=0)\n",
    "    preds = np.argmax(means, axis=1)\n",
    "    preds_std = np.array([std[i, preds[i]] for i in range(len(preds))])\n",
    "\n",
    "    return preds, preds_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "9w9jdFSadbHN",
    "outputId": "867d5a9b-de15-4b1a-d0c2-2d50cd3ae94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7258\n",
      "Average standard deviation of classification: 0.13073984\n",
      "Average standard deviation of misclassified samples: 0.17758748\n"
     ]
    }
   ],
   "source": [
    "preds, stds = get_predictions_with_uncertainty(model, x_test)\n",
    "labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "print('Accuracy: ' + str((preds == labels).sum()/len(labels)))\n",
    "\n",
    "misclassified_mask = labels != preds\n",
    "\n",
    "print('Average standard deviation of classification: ' + str(np.mean(stds)))\n",
    "print('Average standard deviation of misclassified samples: ' + str(np.mean(stds[misclassified_mask])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wK55z8QodbHQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Uncertainty on CIFAR10 using Monte Carlo Dropout.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
